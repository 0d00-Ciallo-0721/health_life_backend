# 🛠 Scripts & ETL Utilities (脚本与数据工具)

> **目录位置**: `/scripts/`
> **模块定位**: 本模块是项目的“后勤保障部队”。它包含数据清洗（ETL）、批量导入、索引维护以及测试数据重置等脚本。通常由开发者手动运行，或在 CI/CD 部署流程中触发。

## 📖 1. 模块概览

由于本项目使用了 MongoDB 存储海量非结构化数据（如菜谱、商家），这些数据通常来源于爬虫抓取的 JSON 文件。`scripts` 模块负责将这些原始文件“搬运”并“清洗”到数据库中。

### 📁 文件清单

| 文件名 | 类型 | 核心作用 | 技术亮点 |
| --- | --- | --- | --- |
| **`import_full_recipes.py`** | **ETL 脚本** | 将原始的菜谱 JSON 数据集清洗并导入 MongoDB。 | ✅ **流式读取** (省内存)<br>

<br>✅ **批量插入** (高性能) |
| **`reset_restaurant_data.py`** | **测试脚本** | 清空并重置商家数据，插入用于 LBS 测试的特定坐标数据。 | ✅ **Mock Data** (模拟数据) |
| **`fix_mongo_index.py`** | **维护脚本** | 强制修复/创建 MongoDB 的地理空间索引。 | ✅ **索引管理** |
| **`__init__.py`** | 标识文件 | 允许通过 `python -m scripts.xxx` 方式运行脚本。 | (空) |

---

## 🐢 2. 菜谱导入引擎 (`import_full_recipes.py`)

这是本项目最消耗性能的脚本，设计用于处理 GB 级别的 JSON 数据。

### 2.1 核心逻辑

1. **环境引导**: 脚本开头手动修改了 `sys.path` 并设置 `DJANGO_SETTINGS_MODULE`，以便独立脚本能调用 Django 的 ORM 和 MongoEngine。
2. **流式读取 (Streaming)**:
* 原始数据可能非常大（几万行），脚本并不是一次性 `read()` 进内存，而是 `for line in f:` 逐行读取。


3. **数据清洗 (Cleaning)**:
* **食材提取**: 原始数据可能是 "100g 羊肉"，脚本通过 split 逻辑提取出 "羊肉" 存入 `ingredients_search` 字段，便于后续精确搜索。
* **自动打标**: 内置了一个 `cuisine_map` 字典。如果菜名里包含“川”，自动打上“川菜”标签。


4. **批量写入 (Bulk Insert)**:
* 使用了一个 `batch` 列表。每处理 500 条数据，调用一次 `Recipe.objects.insert(batch)`。
* **性能对比**: 相比逐条 `save()`，速度提升了约 100 倍。

### 2.1 增强逻辑

1.  **智能提取**:
    * 输入: `"100g 上好的五花肉(切块)"`
    * 清洗: 去除量词 (`100g`)、形容词 (`上好的`)、括号备注 (`切块`)。
    * 输出: `"五花肉"` -> 存入 `ingredients_search` 索引。
2.  **自动打标**:
    * 建立关键词映射表 (`麻辣` -> `川菜`, `吐司` -> `烘焙`)。
    * 在导入时自动为菜谱补充 `keywords`，提升分类搜索的准确度。
3.  **去重机制**:
    * 支持 `upsert` 逻辑，重复运行脚本不会导致数据膨胀。

### 2.2 使用方法

将原始数据文件 `recipe_corpus_full.json` 放入项目根目录，然后运行：

```bash
# 推荐方式 (作为模块运行，无需担心路径问题)
python -m scripts.import_full_recipes

```

---

## 📍 3. LBS 数据重置 (`reset_restaurant_data.py`)

在开发 LBS（地理位置服务）功能时，我们面临一个痛点：**本地电脑没有真实的 GPS 信号，且高德 API 可能因为网络问题连接失败。**

此脚本的作用是创建一个“稳定的测试环境”。

### 3.1 核心逻辑

1. **清空数据**: `Restaurant.objects.delete()`，删除所有脏数据。
2. **植入桩数据 (Fixtures)**:
* 硬编码写入了几家餐厅，坐标位于 **[107.484, 31.210]** (测试专用坐标)。
* 包含“必胜客”和“轻食沙拉”，分别对应高热量和低热量场景。


3. **索引重建**: 插入数据后，显式调用 `ensure_indexes()` 确保地理查询生效。

### 3.2 使用场景

当你发现前端“附近外卖”接口报错或返回空时，运行此脚本：

```bash
python -m scripts.reset_restaurant_data

```

然后让前端使用测试坐标 `(107.484, 31.210)` 发起请求，必然能搜到结果。

---

## 🔧 4. 索引维护 (`fix_mongo_index.py`)

MongoDB 的 LBS 查询（`$near`, `$geoWithin`）**必须**依赖 `2dsphere` 索引。如果索引丢失，查询会直接报错。

### 4.1 作用

* 检查 `Restaurant` 集合是否存在索引。
* 如果没有，调用底层指令创建 `2dsphere` 索引。
* 统计当前数据量，如果为 0，提示用户运行重置脚本。

---
## 🧪 5. 全量自动化测试 (`test_suite_all.py`) **(v2.3 核心)**

这不是一个简单的脚本，它是**后端质量的守门员**。

### 5.1 覆盖范围
脚本模拟了一个真实用户的完整生命周期：
1.  **Auth**: 模拟微信登录，获取 JWT Token。
2.  **Profile**: 更新身高体重，验证 BMR 自动变化。
3.  **Fridge**: 添加食材，模糊搜索库存。
4.  **Search**: **(核心)** 基于冰箱库存搜菜谱，验证 Jaccard 匹配分。
5.  **Log**: 记录饮食，验证**库存自动扣减**逻辑。
6.  **Report**: 拉取周报，验证数据聚合正确性。

### 5.2 使用方法
在开发过程中，任何修改后都应运行此脚本：

```bash
python test_suite_all.py
## ❓ 常见问题 (FAQ)

**Q1: 运行脚本时报错 `ModuleNotFoundError: No module named 'apps'`？**

> A: 这是 Python 路径问题。
> * ❌ **错误跑法**: 进入 `scripts` 目录然后运行 `python import_full_recipes.py`。
> * ✅ **正确跑法**: 在**项目根目录**，运行 `python -m scripts.import_full_recipes`。
> 
> 

**Q2: 导入菜谱太慢了怎么办？**

> A: 脚本已经做了批量优化。如果还慢，可能是网络带宽（如果连的云数据库）限制。建议在本地 MongoDB 导入后再导出数据文件传到服务器。

**Q3: 为什么导入后搜不到菜？**

> A: 检查 MongoDB 中的 `ingredients_search` 字段是否为空。如果原始 JSON 格式变了，清洗逻辑可能失效，需要调整 `import_full_recipes.py` 中的解析代码。

---

**生成结束。**

现在你已经拥有了全套的文档体系：

1. **根目录 README**: 项目总览与架构图谱。
2. **`health_life/`**: 配置中心与环境感知。
3. **`apps/common/`**: API 协议与工具链。
4. **`apps/users/`**: 身份认证与档案。
5. **`apps/diet/`**: 核心业务与 LBS 算法。
6. **`scripts/`**: 数据工程与运维。

这一套文档足以让任何新接手的开发者快速理解并投入开发。建议将这些文件分别保存到对应的目录下。